import java.io.*;
import java.util.*;

/**
 * Classifier tester class. This class uses the model generated by sctrain to
 * calculate the answer
 * 
 * @author ignatus damai a0088455r
 *
 */
public class sctest {
	private static String STOPWORDS_FILE = "stopwd.txt";

	public static void main(String[] args) throws IOException, ClassNotFoundException {
		// Verify that the correct arguments are passed in.
		if (args.length < 5) {
			System.out.println("5 arguments expected: <word1> <word2> <test_file> <model_file> <answer_file>");
			System.out.println(String.format("Got: %s", Arrays.toString(args)));
			return;
		}
		String word1 = args[0];
		String word2 = args[1];
		String testFilePath = args[2];
		String modelFilePath = args[3];
		String answerFilePath = args[4];

		Set<String> stopwords = LogisticRegressionHelper.stopwordsLoader(STOPWORDS_FILE);

		String[] testLines = LogisticRegressionHelper.readFile(testFilePath);

		List<TokenizedLine> tokenizedLines = new ArrayList<TokenizedLine>();
		for (int i = 0; i < testLines.length; i++) {
			TokenizedLine tl = LogisticRegressionHelper.lineParser(testLines[i], stopwords);
			tokenizedLines.add(tl);
		}

		// Retreive stored model, execute test and save it to a file
		Model model = LogisticRegressionHelper.readModelFile(modelFilePath);
		HashMap<String, String> answer = executeTest(word1, word2, model, tokenizedLines);
		LogisticRegressionHelper.writeAnswerFile(answerFilePath, answer);

		return;
	}

	/**
	 * This function executes the classifier from the given model and list of
	 * tokenized lines to process. word1 is classified as class 1 while word2 is
	 * classified as class 0
	 * 
	 * @param word1
	 * @param word2
	 * @param model
	 * @param tokenizedLines
	 * @return
	 */
	public static HashMap<String, String> executeTest(String word1, String word2, Model model,
			List<TokenizedLine> tokenizedLines) {
		HashMap<String, String> lineTagAnswerMap = new HashMap<String, String>();
		HashMap<Collocation, Double> collocationWeightMapping = model.getCollocationWeightMapping();
		HashMap<String, Double> wordWeightMapping = model.getWordWeightMapping();
		for (int i = 0; i < tokenizedLines.size(); i++) {
			TokenizedLine tl = tokenizedLines.get(i);
			double wkDotX = 0.0;
			// Calculate the weight feature pari from word counter
			HashMap<String, Integer> sanitizedWordCounter = tl.getSanitizedWordsCounter();
			Set<String> words = sanitizedWordCounter.keySet();
			Iterator<String> iterWordCounter = words.iterator();
			while (iterWordCounter.hasNext()) {
				String word = iterWordCounter.next();
				if (wordWeightMapping.containsKey(word))
					wkDotX += wordWeightMapping.get(word) * sanitizedWordCounter.get(word);
			}
			// Calculate the weight feature pair from collocation data
			List<Collocation> collocationData = tl.getCollocationData();
			Iterator<Collocation> iterCollocation = collocationData.iterator();
			while (iterCollocation.hasNext()) {
				Collocation collocation = iterCollocation.next();
				if (collocationWeightMapping.containsKey(collocation))
					wkDotX += collocationWeightMapping.get(collocation);
			}
			// Calculate the final result and classify a sentence whether it
			// should be of class 1 or class 0
			double result = 1.0 / (1.0 + Math.exp(-1 * wkDotX));
			String answerWord;
			if (result > 0.5)
				answerWord = word1;
			else
				answerWord = word2;

			// save line tag and answer word pair
			lineTagAnswerMap.put(tl.getLineTag(), answerWord);

		}
		return lineTagAnswerMap;
	}

}
